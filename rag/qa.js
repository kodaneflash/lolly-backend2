import { getVectorStore } from "./store.js";
import OpenAI from "openai";
import axios from "axios";

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// Expression ‚Üí animations valides
const expressionToAnimations = {
  smile: ["Talking_0", "Talking_1", "Laughing"],
  angry: ["Angry", "Idle"],
  surprised: ["Terrified", "Talking_2"],
  default: ["Idle", "Talking_2"]
};

// D√©termine une animation coh√©rente
function getAnimationForExpression(expression = "default") {
  const list = expressionToAnimations[expression] || expressionToAnimations["default"];
  return list[Math.floor(Math.random() * list.length)];
}

// Analyse le ton pour d√©terminer une expression faciale
export async function detectFacialExpression(text) {
  try {
    const completion = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        {
          role: "system",
          content: `Analyse le ton de ce message utilisateur et r√©ponds uniquement par l'une de ces expressions : smile, sad, angry, surprised, funnyFace, default.`
        },
        { role: "user", content: text }
      ],
      temperature: 0.3,
      max_tokens: 5
    });

    const expression = completion.choices[0].message.content.trim().toLowerCase();
    return expressionToAnimations[expression] ? expression : "default";
  } catch (err) {
    console.error("‚ùå Erreur d'analyse du ton:", err);
    return "default";
  }
}

function truncateText(text, maxTokens) {
  return text.split(/\s+/).slice(0, maxTokens).join(" ");
}

function isGenericQuestion(input) {
  const keywords = [
    "technologie", "innovation", "produits",
    "services", "solutions", "entreprise",
    "d√©veloppement", "savoir-faire"
  ];
  return keywords.some(word => input.toLowerCase().includes(word));
}

function refineQuestionForNeemba(input) {
  return `Parle-moi de ${input} chez Neemba.`;
}

async function fetchWebsiteData(url = "https://neemba.com") {
  try {
    const { data } = await axios.get(url);
    return data;
  } catch (error) {
    console.error("‚ùå √âchec r√©cup√©ration site Neemba:", error.message);
    return null;
  }
}

// MAIN RAG FUNCTION
export async function answerWithRAG(userMessage, maxContextTokens = 1000) {
  if (isGenericQuestion(userMessage)) {
    console.log("üîπ Reformulation de la question pour Neemba.");
    userMessage = refineQuestionForNeemba(userMessage);
  }

  const relevantDocs = await getVectorStore().then(vectorStore =>
    vectorStore.similaritySearch(userMessage, 1)
  );

  if (relevantDocs.length === 0) {
    return {
      text: "Je suis d√©sol√©, je n'ai pas trouv√© d'informations pertinentes pour r√©pondre √† votre question."
    };
  }

  let websiteData = "";
  const fetchedData = await fetchWebsiteData();
  if (fetchedData) {
    websiteData = truncateText(fetchedData, Math.floor(maxContextTokens / 2));
  }

  const contextChunks = relevantDocs
    .map(doc =>
      truncateText(doc.pageContent, Math.floor(maxContextTokens / 2 / relevantDocs.length))
    )
    .filter(Boolean);

  const context = [...contextChunks, websiteData].filter(Boolean).join("\n---\n");

  const systemPrompt = `
Tu es Agathe, une assistante commerciale professionnelle pour www.neemba.com.

üéØ Ton r√¥le :
- Dire bonjour et te pr√©senter quand on te le demande.
- Pr√©senter les produits/services de Neemba de fa√ßon pr√©cise , longue et d√©taill√©e.
- Fournir des r√©ponses claires, pr√©cises et professionnelles.
- Si une question est trop vague, invite √† la reformuler en lien avec Neemba.
- Tu ne r√©ponds qu'√† propos de Neemba. Hors p√©rim√®tre = r√©ponse neutre.
- Tu ne fais pas de blagues.
- Il est inutile de dire d'aller sur le site web neemba.com car les utilisateurs sont d√©j√† sur le site web 
- Tu comprends les pr√©f√©rences et les comportements des utilisateurs, t'adaptant au ton et au style de conversation.
- Sur des questions de produits/services, tu es factuelle et pr√©cise et donne un maximum d'informations sur le produit et ses caract√©ristiques afin de renseigner au maximum l'utilisateur.

üß† Contexte :
${context}

üìù R√©dige une r√©ponse longue (minimum 3 paragraphes), structur√©e, informative. Ne r√©ponds qu'en texte brut. Ne tronque pas.
`.trim();

  try {
    const completion = await openai.chat.completions.create({
      model: "gpt-4-turbo",
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: userMessage }
      ],
      max_tokens: 1000, // pour une r√©ponse longue
      temperature: 0.7
    });

    const text = completion.choices[0].message.content.trim();
    return { text };
  } catch (err) {
    console.error("‚ùå Erreur RAG:", err);
    return {
      text: "Erreur de traitement, r√©essaie plus tard."
    };
  }
}
