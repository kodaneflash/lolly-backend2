import { ingestDocuments } from "./ingest.js";
import { getVectorStore } from "./store.js";
import OpenAI from "openai";
import axios from "axios";

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// Expression â†’ animations valides
const expressionToAnimations = {
  smile: ["Talking_0", "Talking_1", "Laughing"],
  sad: ["Crying", "Idle"],
  angry: ["Angry", "Rumba"],
  surprised: ["Terrified", "Talking_2"],
  funnyFace: ["Rumba", "Laughing"],
  default: ["Idle", "Talking_2"]
};

function getAnimationForExpression(expression = "default") {
  const list = expressionToAnimations[expression] || expressionToAnimations["default"];
  return list[Math.floor(Math.random() * list.length)];
}

async function detectFacialExpression(text) {
  try {
    const completion = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        {
          role: "system",
          content: `Analyse le ton de ce message utilisateur et rÃ©ponds uniquement par l'une de ces expressions : smile, sad, angry, surprised, funnyFace, default.`
        },
        { role: "user", content: text }
      ],
      temperature: 0.3,
      max_tokens: 5
    });

    const expression = completion.choices[0].message.content.trim().toLowerCase();
    return expressionToAnimations[expression] ? expression : "default";
  } catch (err) {
    console.error("âŒ Erreur d'analyse du ton:", err);
    return "default";
  }
}

function truncateText(text, maxTokens) {
  return text.split(/\s+/).slice(0, maxTokens).join(" ");
}

function isGenericQuestion(input) {
  const keywords = [
    "technologie", "innovation", "produits",
    "services", "solutions", "entreprise",
    "dÃ©veloppement", "savoir-faire"
  ];
  return keywords.some(word => input.toLowerCase().includes(word));
}

function refineQuestionForNeemba(input) {
  return `Parle-moi de ${input} chez Neemba.`;
}

async function fetchWebsiteData(url = "https://neemba.com") {
  try {
    const { data } = await axios.get(url);
    return data;
  } catch (error) {
    console.error("âŒ Ã‰chec rÃ©cupÃ©ration site Neemba:", error.message);
    return null;
  }
}

// MAIN RAG FUNCTION
export async function answerWithRAG(userMessage, maxContextTokens = 1000) {
  if (isGenericQuestion(userMessage)) {
    console.log("ğŸ”¹ Reformulation de la question pour Neemba.");
    userMessage = refineQuestionForNeemba(userMessage);
  }

  const relevantDocs = await getVectorStore().then(vectorStore =>
    vectorStore.similaritySearch(userMessage, 1)
  );

  if (relevantDocs.length === 0) {
    return {
      messages: [
        {
          text: "Je suis dÃ©solÃ©, je n'ai pas trouvÃ© d'informations pertinentes pour rÃ©pondre Ã  votre question.",
          facialExpression: "neutral",
          animation: "Idle"
        }
      ]
    };
  }

  let websiteData = "";
  const fetchedData = await fetchWebsiteData();
  if (fetchedData) {
    websiteData = truncateText(fetchedData, Math.floor(maxContextTokens / 2));
  }

  const contextChunks = relevantDocs
    .map(doc =>
      truncateText(doc.pageContent, Math.floor(maxContextTokens / 2 / relevantDocs.length))
    )
    .filter(Boolean);

  const context = [...contextChunks, websiteData].filter(Boolean).join("\n---\n");

  const systemPrompt = `
Tu es Agathe, une assistante commerciale professionnelle pour www.neemba.com.

ğŸ¯ Ton rÃ´le :
- Dire bonjour et te prÃ©senter quand on te le demande.
- PrÃ©senter les produits/services de Neemba de faÃ§on prÃ©cise , longue et dÃ©taillÃ©e.
- Fournir des rÃ©ponses claires, prÃ©cises et professionnelles.
- Si une question est trop vague, invite Ã  la reformuler en lien avec Neemba.
- Tu ne rÃ©ponds qu'Ã  propos de Neemba. Hors pÃ©rimÃ¨tre = rÃ©ponse neutre.
- Tu ne fais pas de blagues.
- Il est inutile de dire d'aller sur le site web neemba.com car les utilisateurs sont dÃ©jÃ  sur le site.
- Tu comprends les prÃ©fÃ©rences et les comportements des utilisateurs, t'adaptant au ton et au style de conversation.
- Sur des questions de produits/services, tu es factuelle et prÃ©cise et donne un maximum d'informations sur le produit et ses caractÃ©ristiques afin de renseigner au maximum l'utilisateur.

ğŸ§  Contexte :
${context}

ğŸ“ Structure ta rÃ©ponse en **plusieurs messages courts** (1 Ã  3 phrases chacun, max 3 messages au total). Chaque message sera animÃ© individuellement.
ğŸ“ Garde la rÃ©ponse globale concise (environ 100 Ã  150 mots maximum).

ğŸ¯ RÃ©ponds uniquement au format JSON :

{
  "messages": [
    {
      "text": "Une rÃ©ponse concise en une ou deux phrases.",
      "source": "https://...",
      "image": "https://..."
    },
    {
      "text": "Une autre phrase pour enchaÃ®ner.",
      "source": "https://...",
      "image": "https://..."
    }
  ]
}

ğŸ›‘ Ne parle jamais en dehors du JSON. Pas de texte hors JSON.
Toujours rÃ©pondre en franÃ§ais.
`.trim();

  try {
    const completion = await openai.chat.completions.create({
      model: "gpt-4-turbo",
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: userMessage }
      ],
      max_tokens: 350,
      temperature: 0.7,
      response_format: { type: "json_object" }
    });

    const parsed = JSON.parse(completion.choices[0].message.content);
    const messages = parsed.messages || [];

    const enrichedMessages = [];

    for (const msg of messages) {
      const facialExpression = await detectFacialExpression(msg.text);
      const animation = getAnimationForExpression(facialExpression);
      enrichedMessages.push({
        ...msg,
        facialExpression,
        animation
      });
    }

    return { messages: enrichedMessages };
  } catch (err) {
    console.error("âŒ Erreur RAG:", err);
    return {
      messages: [
        {
          text: "Erreur de traitement, rÃ©essaie plus tard.",
          facialExpression: "sad",
          animation: "Crying"
        }
      ]
    };
  }
}
