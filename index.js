// index.js
import express from "express";
import cors from "cors";
import dotenv from "dotenv";
import { answerWithRAG } from "./rag/qa.js";
import { ingestDocuments } from "./rag/ingest.js";
import {
  generateSpeechWithStreaming,
  lipSyncMessage,
  audioFileToBase64,
  readJsonTranscript,
  ensureAudiosDirectory,
} from "./lib/audioUtils.js";


dotenv.config();

const app = express();
// Ajoute Ã§a immÃ©diatement aprÃ¨s app = express();
app.use(cors({
  origin: "https://neemba-frontend.vercel.app",
  methods: ["GET", "POST"],
  credentials: true
}));

const port = process.env.PORT || 3000;



app.use(express.json());

// Serve les fichiers audio statiquement
app.use("/audios", express.static("audios"));

// Endpoint de test pour Elastic Beanstalk
app.get("/", (req, res) => {
  res.send("âœ… Neemba backend is running.");
});

// Endpoint principal
app.post("/chat", async (req, res) => {
  try {
    await ensureAudiosDirectory();

    const userMessage = req.body.message;
    if (!userMessage) {
      return res.status(400).json({ error: "Missing message." });
    }

    const ragResponse = await answerWithRAG(userMessage);
    const messages = ragResponse.messages;

    const processedMessages = await Promise.all(
      messages.map(async (msg, i) => {
        const id = `${Date.now()}_${i}`;
        const mp3Path = `./audios/message_${id}.mp3`;
        const jsonPath = `./audios/message_${id}.json`;
    
        try {
          console.log(`ğŸ¤ Generating speech for message ${i}...`);
          await generateSpeechWithStreaming(msg.text, mp3Path);
    
          console.log(`ğŸ‘„ Starting lipsync for message ${i}...`);
          await lipSyncMessage(id);
    
          console.log(`ğŸ“¤ Converting audio to base64...`);
          const audioBase64 = await audioFileToBase64(mp3Path);
    
          console.log(`ğŸ“– Reading lipsync JSON...`);
          const lipsyncData = await readJsonTranscript(jsonPath);
    
          return {
            ...msg,
            audio: audioBase64,
            lipsync: lipsyncData,
          };
        } catch (err) {
          console.error(`âŒ Audio/lipsync processing failed for message ${i}:`, err.message);
          return {
            ...msg,
            audio: null,
            lipsync: null,
            error: err.message || "Unknown error"
          };
        }
      })
    );
    

    res.status(200).json({ messages: processedMessages });
  } catch (error) {
    console.error("âŒ Chat endpoint error:", error);
    res.status(500).json({ error: "Internal server error" });
  }
});

// DÃ©marrage de l'API avec ingestion de documents
const startServer = async () => {
  try {
    console.log("âš™ï¸ Ingesting documents...");
    await ingestDocuments();
    console.log("ğŸ“š Documents ingested successfully.");

    app.listen(port, "0.0.0.0", () => {
      console.log(`ğŸš€ Neemba API listening on port ${port}`);
    });
  } catch (err) {
    console.error("âŒ Fatal error on startup:", err);
    process.exit(1);
  }
};

startServer();
